---
created: 2025-11-10T18:30:00+01:00
updated: 2025-11-10T18:30:00+01:00
type: backlog-item
tags: [backlog-item, optimization, performance, python, duplicate-detection]
status: todo
priority: medium
estimated_time: "3-4h"
category: improvement
project: pkm-system
phase: phase-2
related_to: 
  - "[[chat_to_cards]]"
  - "[[postprocess_cards]]"
  - "[[DuplicateDetector]]"
---

# üöÄ Optimize Duplicate Detection Performance

> **Am√©liorer les performances de la d√©tection de doublons pour supporter des sessions de 2000+ cartes**

---

## üìã Description

La d√©tection de doublons devient extr√™mement lente sur les grandes conversations (1000+ cartes).

### Probl√®me Actuel

**Algorithme O(n¬≤) :**
- Compare chaque carte avec toutes les autres
- 1049 cartes = 549,876 comparaisons
- 1887 cartes = 1,779,141 comparaisons
- **Freeze/timeout** sur grosses sessions

**Impact :**
- Batch processing bloqu√©
- Timeout sur conversations volumineuses
- Exp√©rience utilisateur d√©grad√©e

### Contexte D√©couverte

Identifi√© lors du batch processing de 35 conversations historiques :
- Sessions < 200 cartes : rapide ‚úÖ
- Sessions 500-1000 : lent mais passe ‚ö†Ô∏è
- Sessions 1000+ : freeze total üî¥

**Conversations probl√©matiques :**
- "French chat message instructions" : 1049 cartes
- "Ticket receipt data extraction (Power BI)" : 1887 cartes

---

## üéØ Objectif

Optimiser la d√©tection de doublons pour :
- ‚úÖ Supporter 2000+ cartes sans timeout
- ‚úÖ Temps de traitement < 30s pour 2000 cartes
- ‚úÖ Pas de r√©gression de pr√©cision
- ‚úÖ Code maintenable et test√©

---

## üîß Solutions Possibles

### Option 1 : Hashing + Grouping (Recommand√©)

**Principe :**
```python
# Pre-grouper par hash du contenu
groups = {}
for card in cards:
    hash_key = hash(card.content[:200])  # Hash premiers chars
    groups[hash_key].append(card)

# Comparer uniquement dans chaque groupe
for group in groups.values():
    compare_within_group(group)
```

**Avantages :**
- Complexit√© O(n log n)
- R√©duction massive des comparaisons
- Pr√©cision conserv√©e

**Inconv√©nients :**
- Code plus complexe
- Besoin de tuner la fonction de hash

---

### Option 2 : Sampling Intelligent

**Principe :**
```python
# √âchantillonner strat√©giquement
if len(cards) > 500:
    sample = strategic_sample(cards, max_size=500)
    duplicates = detect_in_sample(sample)
```

**Avantages :**
- Tr√®s rapide
- Simple √† impl√©menter

**Inconv√©nients :**
- Perte de pr√©cision
- Peut manquer des doublons

---

### Option 3 : Incremental Detection

**Principe :**
```python
# Cache des comparaisons d√©j√† faites
cache = load_comparison_cache()

# Comparer uniquement nouvelles vs existantes
for new_card in new_cards:
    for existing_card in existing_cards:
        if (new_card.id, existing_card.id) not in cache:
            similarity = compare(new_card, existing_card)
            cache[(new_card.id, existing_card.id)] = similarity
```

**Avantages :**
- √âvite recomputation
- Parfait pour ajouts incr√©mentaux

**Inconv√©nients :**
- Gestion du cache complexe
- Peu adapt√© au batch

---

### Option 4 : Multiprocessing

**Principe :**
```python
# Parall√©liser les comparaisons
with Pool(cpu_count()) as pool:
    results = pool.starmap(compare_pair, card_pairs)
```

**Avantages :**
- Speedup lin√©aire avec cores
- Pas de changement d'algorithme

**Inconv√©nients :**
- Overhead cr√©ation processes
- Complexit√© multiprocessing

---

## üì¶ Plan d'Impl√©mentation

### Phase 1 : Profiling (30min-1h)

**Objectifs :**
- [ ] Identifier bottlenecks exacts
- [ ] Mesurer temps par √©tape
- [ ] √âtablir baseline performance

**Actions :**
```bash
# Profiler avec cProfile
python -m cProfile -o profile.stats scripts/chat-atomizer/chat_to_cards.py ...

# Analyser r√©sultats
python -m pstats profile.stats
```

**Livrables :**
- Rapport de profiling
- Identification goulots
- M√©triques baseline

---

### Phase 2 : Impl√©mentation Hashing (1-2h)

**Objectifs :**
- [ ] Impl√©menter grouping par hash
- [ ] Adapter DuplicateDetector
- [ ] Tests unitaires

**Code skeleton :**
```python
class OptimizedDuplicateDetector:
    @staticmethod
    def hash_content(content: str, length: int = 200) -> int:
        """Hash les premiers chars du contenu."""
        return hash(content[:length])
    
    @staticmethod
    def group_by_hash(cards: List[Card]) -> Dict[int, List[Card]]:
        """Groupe les cartes par hash."""
        groups = {}
        for card in cards:
            h = OptimizedDuplicateDetector.hash_content(card.content)
            groups.setdefault(h, []).append(card)
        return groups
    
    @staticmethod
    def find_duplicates_optimized(
        cards: List[Card], 
        threshold: float = 0.85
    ) -> List[Tuple[Card, Card, float]]:
        """D√©tection optimis√©e O(n log n)."""
        groups = OptimizedDuplicateDetector.group_by_hash(cards)
        duplicates = []
        
        for group_cards in groups.values():
            # Comparer uniquement dans le groupe
            duplicates.extend(
                compare_within_group(group_cards, threshold)
            )
        
        return duplicates
```

**Tests :**
```python
def test_optimized_detector_performance():
    # G√©n√©rer 2000 cartes
    cards = generate_test_cards(2000)
    
    # Mesurer temps
    start = time.time()
    duplicates = OptimizedDuplicateDetector.find_duplicates_optimized(cards)
    duration = time.time() - start
    
    assert duration < 30, f"Too slow: {duration}s"
    assert len(duplicates) >= 0  # Au moins ne crash pas
```

---

### Phase 3 : Benchmarks (30min)

**Objectifs :**
- [ ] Comparer performances avant/apr√®s
- [ ] V√©rifier pr√©cision conserv√©e
- [ ] Documenter gains

**M√©triques :**
| Cards | Before | After | Speedup |
|-------|--------|-------|---------|
| 100   | 2s     | ?     | ?x      |
| 500   | 30s    | ?     | ?x      |
| 1000  | 180s   | ?     | ?x      |
| 2000  | timeout| ?     | ?x      |

---

## üß™ Crit√®res d'Acceptation

### Performance

- [ ] 2000 cartes : < 30s
- [ ] 1000 cartes : < 10s
- [ ] 500 cartes : < 3s

### Qualit√©

- [ ] Pr√©cision d√©tection conserv√©e (>95%)
- [ ] Tests unitaires passent
- [ ] Code document√©
- [ ] Pas de r√©gression sur petites sessions

### Documentation

- [ ] README updated
- [ ] Benchmarks document√©s
- [ ] Guide utilisation

---

## üîó R√©f√©rences

**Code actuel :**
- `scripts/chat-atomizer/postprocess_cards.py` ‚Üí `DuplicateDetector`
- `scripts/chat-atomizer/chat_to_cards.py` ‚Üí Step 2: Duplicate Detection

**Conversations li√©es :**
- [[Session 2025-11-10 - Chat Atomization Batch]]
- Batch processing 35 conversations

**Ressources techniques :**
- Algorithme similarit√© actuel : difflib.SequenceMatcher
- Alternative possible : rapidfuzz (plus rapide)

---

## üí° Notes

### Workaround Actuel

Pour le batch processing, les steps 2-5 ont √©t√© comment√©s :
```python
# Steps 2-5 d√©sactiv√©s temporairement
# - Duplicate detection
# - Duplicate removal
# - Intelligent renaming
# - Link updates
```

Cela permet de finir le batch mais :
- ‚ùå Doublons non d√©tect√©s
- ‚ùå Noms de cartes basiques
- ‚ùå Pas de cleanup

### Alternative : Script Post-Processing

Cr√©er un script s√©par√© qui :
1. Charge toutes les sessions g√©n√©r√©es
2. D√©tecte doublons cross-sessions (optionnel)
3. Nettoie/renomme en batch
4. Plus efficace qu'√† la vol√©e

---

## üìÖ Timeline Estim√©e

**Total : 3-4h**

| Phase | Dur√©e | Status |
|-------|-------|--------|
| Profiling | 30min-1h | ‚¨ú Todo |
| Implementation | 1-2h | ‚¨ú Todo |
| Testing | 30min | ‚¨ú Todo |
| Benchmarks | 30min | ‚¨ú Todo |
| Documentation | 30min | ‚¨ú Todo |

---

## ‚úÖ Checklist Completion

### D√©veloppement

- [ ] Profiling r√©alis√©
- [ ] Hashing impl√©ment√©
- [ ] Grouping impl√©ment√©
- [ ] Tests unitaires ajout√©s
- [ ] Benchmarks r√©alis√©s

### Quality Assurance

- [ ] Performance targets atteints
- [ ] Pr√©cision v√©rifi√©e
- [ ] Pas de r√©gression
- [ ] Code review fait

### Documentation

- [ ] README updated
- [ ] Code comment√©
- [ ] Benchmarks document√©s
- [ ] Backlog item closed

---

**Cr√©√© pendant :** [[Session 2025-11-10 - Chat Atomization Batch]]  
**Phase projet :** Phase 2 - Features & Optimization  
**Assign√© √† :** √Ä d√©finir  
**Bloquant :** Non (workaround actif)
